{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "# Membaca data hasil preprocessing\n",
    "df = pd.read_csv('data/preprocessed/preprocessed_genshin.csv')\n",
    "\n",
    "# Representasi teks menggunakan TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = tfidf.fit_transform(df['snippet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cluster Distribution:\n",
      "cluster\n",
      "2    56\n",
      "4    48\n",
      "0    39\n",
      "3    34\n",
      "1    22\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balanced Cluster Distribution:\n",
      "cluster\n",
      "4    40\n",
      "1    40\n",
      "3    40\n",
      "2    40\n",
      "0    39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Menentukan jumlah cluster\n",
    "n_clusters = 5  # Sesuaikan jumlah cluster sesuai kebutuhan\n",
    "\n",
    "# KMeans dengan inisialisasi k-means++ untuk pembagian lebih baik\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, init='k-means++')\n",
    "\n",
    "# Melakukan clustering\n",
    "df['cluster'] = kmeans.fit_predict(tfidf_matrix)\n",
    "\n",
    "# Menampilkan distribusi awal cluster\n",
    "print(\"Initial Cluster Distribution:\")\n",
    "print(df['cluster'].value_counts())\n",
    "\n",
    "# Fungsi untuk memastikan tiap cluster memiliki 35-40 data\n",
    "def balance_clusters(df, min_size=150, max_size=200, n_clusters=5):\n",
    "    # Cek ukuran cluster\n",
    "    cluster_sizes = df['cluster'].value_counts()\n",
    "    \n",
    "    while True:\n",
    "        # Cek apakah semua cluster sudah memenuhi batasan (35 <= size <= 40)\n",
    "        if all(min_size <= size <= max_size for size in cluster_sizes):\n",
    "            break\n",
    "        \n",
    "        # Temukan cluster yang lebih besar dari max_size dan lebih kecil dari min_size\n",
    "        large_clusters = cluster_sizes[cluster_sizes > max_size].index\n",
    "        small_clusters = cluster_sizes[cluster_sizes < min_size].index\n",
    "        \n",
    "        # Jika tidak ada cluster yang terlalu besar atau kecil, berhenti\n",
    "        if large_clusters.empty and small_clusters.empty:\n",
    "            break\n",
    "        \n",
    "        # Ambil data dari cluster yang lebih besar dan pindahkan ke cluster yang lebih kecil\n",
    "        for large_cluster in large_clusters:\n",
    "            # Ambil data dari cluster besar\n",
    "            large_cluster_data = df[df['cluster'] == large_cluster]\n",
    "            # Tentukan jumlah data yang perlu dipindahkan\n",
    "            excess_data_count = len(large_cluster_data) - max_size\n",
    "            \n",
    "            # Ambil sampel acak dari data yang berlebih\n",
    "            data_to_move = large_cluster_data.sample(n=excess_data_count, random_state=42)\n",
    "            \n",
    "            # Pilih cluster kecil untuk menerima data\n",
    "            for small_cluster in small_clusters:\n",
    "                if len(df[df['cluster'] == small_cluster]) < max_size:\n",
    "                    # Pindahkan data ke cluster kecil\n",
    "                    df.loc[data_to_move.index, 'cluster'] = small_cluster\n",
    "                    break  # Hanya pindahkan ke satu cluster kecil\n",
    "\n",
    "        # Perbarui ukuran cluster setelah pemindahan\n",
    "        cluster_sizes = df['cluster'].value_counts()\n",
    "\n",
    "    return df\n",
    "\n",
    "# Seimbangkan cluster\n",
    "df = balance_clusters(df, min_size=35, max_size=40, n_clusters=5)\n",
    "\n",
    "# Menampilkan distribusi akhir cluster\n",
    "print(\"\\nBalanced Cluster Distribution:\")\n",
    "print(df['cluster'].value_counts())\n",
    "\n",
    "# Menampilkan data beberapa baris sebagai contoh\n",
    "# print(\"\\nSample of balanced data:\")\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     title                                            snippet  \\\n",
      "103             Freydy Voo  started first release really love graphics cha...   \n",
      "78   Farrell Adra Khalfani  hard give good rating things worth playing gen...   \n",
      "9         Olivia Staringer  uninteresting characters uninteresting dialog ...   \n",
      "67               Sean Arce  pointless playing play games coupon gone might...   \n",
      "158                  Sam B  update gi offers incredible openworld recent s...   \n",
      "\n",
      "     rating  \n",
      "103     5.0  \n",
      "78      2.0  \n",
      "9       1.0  \n",
      "67      1.0  \n",
      "158     5.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Fungsi untuk menghitung kemiripan antara snippet yang dicari dan data di dalam cluster\n",
    "def text_similarity(snippet1, snippet2):\n",
    "    # Menghitung kemiripan teks menggunakan cosine similarity atau metrik lain\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform([snippet1, snippet2])\n",
    "    \n",
    "    # Menghitung cosine similarity antara dua teks\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Fungsi utama rekomendasi berdasarkan snippet\n",
    "def recommend_by_snippet(snippet, df, n_recommendations=5):\n",
    "    # Normalisasi casing dan hilangkan spasi ekstra pada snippet\n",
    "    snippet = snippet.lower().strip()\n",
    "    \n",
    "    # Cari snippet yang paling mirip\n",
    "    df['snippet_similarity'] = df['snippet'].apply(lambda x: text_similarity(snippet, x))\n",
    "    \n",
    "    # Urutkan berdasarkan kemiripan terbesar\n",
    "    similar_snippets = df.sort_values(by='snippet_similarity', ascending=False)\n",
    "    \n",
    "    # Ambil cluster dari snippet yang paling mirip\n",
    "    cluster = similar_snippets.iloc[0]['cluster']\n",
    "    \n",
    "    # Ambil data dari cluster yang sama\n",
    "    cluster_data = df[df['cluster'] == cluster]\n",
    "    \n",
    "    # Jika cluster terlalu kecil (kurang dari jumlah rekomendasi), kurangi jumlah rekomendasi\n",
    "    if len(cluster_data) < n_recommendations:\n",
    "        n_recommendations = len(cluster_data)\n",
    "    \n",
    "    # Urutkan data di dalam cluster berdasarkan kemiripan\n",
    "    cluster_data = cluster_data.sort_values(by='snippet_similarity', ascending=False)\n",
    "    \n",
    "    # Tampilkan ulasan lain dari cluster yang sama\n",
    "    recommendations = cluster_data.head(n_recommendations)  # Ambil n rekomendasi teratas\n",
    "    return recommendations[['title', 'snippet', 'rating']]\n",
    "\n",
    "# Contoh pencarian berdasarkan snippet\n",
    "snippet = \"story\"\n",
    "recommendations = recommend_by_snippet(snippet, df)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.00\n",
      "Recall: 0.13\n",
      "F1-Score: 0.23\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fungsi untuk menghitung kemiripan antara snippet yang dicari dan data di dalam cluster\n",
    "def text_similarity(snippet1, snippet2):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform([snippet1, snippet2])\n",
    "    similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "    return similarity[0][0]\n",
    "\n",
    "# Fungsi utama rekomendasi berdasarkan snippet\n",
    "def recommend_by_snippet(snippet, df, n_recommendations=5):\n",
    "    snippet = snippet.lower().strip()\n",
    "    df['snippet_similarity'] = df['snippet'].apply(lambda x: text_similarity(snippet, x))\n",
    "    similar_snippets = df.sort_values(by='snippet_similarity', ascending=False)\n",
    "    \n",
    "    cluster = similar_snippets.iloc[0]['cluster']\n",
    "    cluster_data = df[df['cluster'] == cluster]\n",
    "    \n",
    "    if len(cluster_data) < n_recommendations:\n",
    "        n_recommendations = len(cluster_data)\n",
    "    \n",
    "    cluster_data = cluster_data.sort_values(by='snippet_similarity', ascending=False)\n",
    "    recommendations = cluster_data.head(n_recommendations)\n",
    "    \n",
    "    return recommendations[['title', 'snippet', 'rating']], cluster_data\n",
    "\n",
    "# Fungsi untuk menghitung Precision dan Recall\n",
    "def evaluate_recommendation(recommended, cluster_data):\n",
    "    # Menghitung relevansi berdasarkan cluster\n",
    "    relevant_items = cluster_data  # Semua item di dalam cluster dianggap relevan\n",
    "    \n",
    "    # Precision = (Jumlah rekomendasi yang relevan) / (Jumlah rekomendasi yang diberikan)\n",
    "    recommended_titles = set(recommended['title'])\n",
    "    relevant_titles = set(relevant_items['title'])\n",
    "    \n",
    "    # Menghitung precision dan recall\n",
    "    true_positives = len(recommended_titles & relevant_titles)\n",
    "    precision = true_positives / len(recommended_titles) if len(recommended_titles) > 0 else 0\n",
    "    recall = true_positives / len(relevant_titles) if len(relevant_titles) > 0 else 0\n",
    "    \n",
    "    # F1-Score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Contoh penggunaan evaluasi\n",
    "snippet = \"gensina\"\n",
    "recommended, cluster_data = recommend_by_snippet(snippet, df)\n",
    "precision, recall, f1 = evaluate_recommendation(recommended, cluster_data)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
