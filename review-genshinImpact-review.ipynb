{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rebecca/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np  # Tambahkan import numpy\n",
    "\n",
    "# Unduh stopwords jika belum\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and Print Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'title', 'avatar', 'rating', 'snippet', 'likes', 'date',\n",
      "       'iso_date', 'response'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>avatar</th>\n",
       "      <th>rating</th>\n",
       "      <th>snippet</th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>iso_date</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e5384431-56f9-43fa-a32a-53296afc7f66</td>\n",
       "      <td>Seraphim</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>While I've reviewed this before, I decided to ...</td>\n",
       "      <td>88</td>\n",
       "      <td>October 09, 2024</td>\n",
       "      <td>2024-10-09T00:08:20Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6a73081f-3490-47ba-89fa-83744cb20940</td>\n",
       "      <td>TWOSTORE !</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Very fun but I wish there was more fighting in...</td>\n",
       "      <td>35</td>\n",
       "      <td>October 12, 2024</td>\n",
       "      <td>2024-10-12T06:39:01Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3a3d4c90-0b6e-45dc-b1e6-014659055bbf</td>\n",
       "      <td>A G</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Fun game, I enjoy the story. There is tons to ...</td>\n",
       "      <td>11</td>\n",
       "      <td>October 30, 2024</td>\n",
       "      <td>2024-10-30T18:01:37Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99015538-1d26-4bd9-a02f-37bc2a361d1a</td>\n",
       "      <td>Astra</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This game is phenomenal. The art style and sce...</td>\n",
       "      <td>77</td>\n",
       "      <td>October 18, 2024</td>\n",
       "      <td>2024-10-18T19:11:12Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>541b3b4d-97f6-42e0-9c68-059a63e1e67f</td>\n",
       "      <td>Angela Williams</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I love this game. However, it is incredibly la...</td>\n",
       "      <td>14</td>\n",
       "      <td>October 14, 2024</td>\n",
       "      <td>2024-10-14T03:04:43Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ad484b6a-1b9c-42ab-9cee-9df6e28f12d4</td>\n",
       "      <td>Valerie</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I used to be obsessed with this game but I hav...</td>\n",
       "      <td>99</td>\n",
       "      <td>October 13, 2024</td>\n",
       "      <td>2024-10-13T14:02:08Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fb25cdf6-40d8-44e8-b1b9-d439ebd88565</td>\n",
       "      <td>Daniel “Chotara” Ricciardi</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Highly recommend. I have been playing the game...</td>\n",
       "      <td>65</td>\n",
       "      <td>October 18, 2024</td>\n",
       "      <td>2024-10-18T15:20:11Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>36e821d3-9441-4eaa-94a7-9c7b9b7463b5</td>\n",
       "      <td>Amy</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Hello! I absolutely love this game! It has inc...</td>\n",
       "      <td>29</td>\n",
       "      <td>October 29, 2024</td>\n",
       "      <td>2024-10-29T00:27:08Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4b1e6dcb-d251-450e-9be6-358b4bb8e9d6</td>\n",
       "      <td>Feitan Desy</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I've been playing this game since January 16th...</td>\n",
       "      <td>64</td>\n",
       "      <td>October 08, 2024</td>\n",
       "      <td>2024-10-08T23:13:09Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27525772-1c0a-40e4-8321-4c5f0a0f7c64</td>\n",
       "      <td>Olivia Staringer</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Uninteresting characters, uninteresting dialog...</td>\n",
       "      <td>14</td>\n",
       "      <td>November 11, 2024</td>\n",
       "      <td>2024-11-11T22:58:07Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id                       title  \\\n",
       "0  e5384431-56f9-43fa-a32a-53296afc7f66                    Seraphim   \n",
       "1  6a73081f-3490-47ba-89fa-83744cb20940                  TWOSTORE !   \n",
       "2  3a3d4c90-0b6e-45dc-b1e6-014659055bbf                         A G   \n",
       "3  99015538-1d26-4bd9-a02f-37bc2a361d1a                       Astra   \n",
       "4  541b3b4d-97f6-42e0-9c68-059a63e1e67f             Angela Williams   \n",
       "5  ad484b6a-1b9c-42ab-9cee-9df6e28f12d4                     Valerie   \n",
       "6  fb25cdf6-40d8-44e8-b1b9-d439ebd88565  Daniel “Chotara” Ricciardi   \n",
       "7  36e821d3-9441-4eaa-94a7-9c7b9b7463b5                         Amy   \n",
       "8  4b1e6dcb-d251-450e-9be6-358b4bb8e9d6                 Feitan Desy   \n",
       "9  27525772-1c0a-40e4-8321-4c5f0a0f7c64            Olivia Staringer   \n",
       "\n",
       "                                              avatar  rating  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/ALV-U...     3.0   \n",
       "1  https://play-lh.googleusercontent.com/a-/ALV-U...     3.0   \n",
       "2  https://play-lh.googleusercontent.com/a-/ALV-U...     3.0   \n",
       "3  https://play-lh.googleusercontent.com/a-/ALV-U...     5.0   \n",
       "4  https://play-lh.googleusercontent.com/a-/ALV-U...     2.0   \n",
       "5  https://play-lh.googleusercontent.com/a-/ALV-U...     3.0   \n",
       "6  https://play-lh.googleusercontent.com/a-/ALV-U...     5.0   \n",
       "7  https://play-lh.googleusercontent.com/a-/ALV-U...     4.0   \n",
       "8  https://play-lh.googleusercontent.com/a-/ALV-U...     4.0   \n",
       "9  https://play-lh.googleusercontent.com/a-/ALV-U...     1.0   \n",
       "\n",
       "                                             snippet  likes  \\\n",
       "0  While I've reviewed this before, I decided to ...     88   \n",
       "1  Very fun but I wish there was more fighting in...     35   \n",
       "2  Fun game, I enjoy the story. There is tons to ...     11   \n",
       "3  This game is phenomenal. The art style and sce...     77   \n",
       "4  I love this game. However, it is incredibly la...     14   \n",
       "5  I used to be obsessed with this game but I hav...     99   \n",
       "6  Highly recommend. I have been playing the game...     65   \n",
       "7  Hello! I absolutely love this game! It has inc...     29   \n",
       "8  I've been playing this game since January 16th...     64   \n",
       "9  Uninteresting characters, uninteresting dialog...     14   \n",
       "\n",
       "                date              iso_date response  \n",
       "0   October 09, 2024  2024-10-09T00:08:20Z      NaN  \n",
       "1   October 12, 2024  2024-10-12T06:39:01Z      NaN  \n",
       "2   October 30, 2024  2024-10-30T18:01:37Z      NaN  \n",
       "3   October 18, 2024  2024-10-18T19:11:12Z      NaN  \n",
       "4   October 14, 2024  2024-10-14T03:04:43Z      NaN  \n",
       "5   October 13, 2024  2024-10-13T14:02:08Z      NaN  \n",
       "6   October 18, 2024  2024-10-18T15:20:11Z      NaN  \n",
       "7   October 29, 2024  2024-10-29T00:27:08Z      NaN  \n",
       "8   October 08, 2024  2024-10-08T23:13:09Z      NaN  \n",
       "9  November 11, 2024  2024-11-11T22:58:07Z      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baca file CSV\n",
    "df = pd.read_csv('data/google-play-rev-gen-2.csv')\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Tampilkan isi kolom 'Nama'\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new Data will be saved to new-review-data/filtered_reviews_gensin.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Membaca data dari file CSV\n",
    "df = pd.read_csv('data/google-play-rev-gen-2.csv')\n",
    "\n",
    "# Memilih kolom yang dibutuhkan\n",
    "columns_to_keep = ['rating', 'snippet', 'likes', 'date', 'iso_date', 'response']\n",
    "filtered_df = df[columns_to_keep]\n",
    "\n",
    "# Membuat direktori jika belum ada\n",
    "output_dir = 'new-review-data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Menyimpan data baru ke file CSV\n",
    "output_file = os.path.join(output_dir, 'filtered_reviews_gensin.csv')\n",
    "filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"new Data will be saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inisialisasi stopwords dan stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data will be processed with cleaned text to new data new-review-data/filter-snippet/filtered_snippet_reviews_gensin.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Muat model bahasa spaCy (pastikan sudah menginstal spaCy dan model bahasa)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Fungsi preprocessing menggunakan spaCy\n",
    "def preprocess_text(text):\n",
    "    # Menghapus karakter khusus dan angka\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text))\n",
    "    \n",
    "    # Tokenisasi dengan spaCy\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    # Lemmatization dan menghapus stopwords\n",
    "    processed_tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]\n",
    "    \n",
    "    # Gabungkan kembali tokens yang telah diproses menjadi teks yang bersih\n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "# Baca dataset filtered_reviews.csv\n",
    "input_file = 'new-review-data/filtered_reviews_gensin.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Terapkan preprocessing pada kolom 'Snippet'\n",
    "df['cleaned_snippet'] = df['snippet'].apply(preprocess_text)  # Pastikan nama kolom case-sensitive\n",
    "\n",
    "# Hapus kolom 'Snippet' yang asli\n",
    "df = df.drop(columns=['snippet'])\n",
    "\n",
    "# Buat direktori baru untuk menyimpan hasil\n",
    "output_dir = 'new-review-data/filter-snippet'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Simpan dataset yang diperbarui\n",
    "output_file = os.path.join(output_dir, 'filtered_snippet_reviews_gensin.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"New data will be processed with cleaned text to new data {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyword Extraction TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ability      able  absolute  absolutely  absurd  abt  abyss  acc  accept  \\\n",
      "0  0.000000  0.000000       0.0         0.0     0.0  0.0    0.0  0.0     0.0   \n",
      "1  0.229202  0.000000       0.0         0.0     0.0  0.0    0.0  0.0     0.0   \n",
      "2  0.000000  0.200019       0.0         0.0     0.0  0.0    0.0  0.0     0.0   \n",
      "3  0.000000  0.000000       0.0         0.0     0.0  0.0    0.0  0.0     0.0   \n",
      "4  0.000000  0.000000       0.0         0.0     0.0  0.0    0.0  0.0     0.0   \n",
      "\n",
      "   accidentally  ...  yeah      year  yep       yes  yesterday  youtube  \\\n",
      "0           0.0  ...   0.0  0.000000  0.0  0.000000        0.0      0.0   \n",
      "1           0.0  ...   0.0  0.000000  0.0  0.000000        0.0      0.0   \n",
      "2           0.0  ...   0.0  0.143681  0.0  0.000000        0.0      0.0   \n",
      "3           0.0  ...   0.0  0.000000  0.0  0.209655        0.0      0.0   \n",
      "4           0.0  ...   0.0  0.000000  0.0  0.000000        0.0      0.0   \n",
      "\n",
      "   youtuber  yrs  zelda  zero  \n",
      "0       0.0  0.0    0.0   0.0  \n",
      "1       0.0  0.0    0.0   0.0  \n",
      "2       0.0  0.0    0.0   0.0  \n",
      "3       0.0  0.0    0.0   0.0  \n",
      "4       0.0  0.0    0.0   0.0  \n",
      "\n",
      "[5 rows x 1469 columns]\n",
      "Hasil TF-IDF disimpan ke new-review-data/filter-snippet/tfidf_filtered_snippet_reviews_gensin.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Baca dataset baru yang telah diproses\n",
    "input_file = 'new-review-data/filter-snippet/filtered_snippet_reviews_gensin.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Pastikan kolom 'cleaned_snippet' ada\n",
    "if 'cleaned_snippet' not in df.columns:\n",
    "    raise ValueError(\"Kolom 'cleaned_snippet' tidak ditemukan dalam dataset. Periksa file input.\")\n",
    "\n",
    "# Inisialisasi TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')  # Gunakan stop_words built-in dari scikit-learn\n",
    "\n",
    "# Fit dan transform data ulasan yang telah diproses menggunakan TF-IDF\n",
    "X_tfidf = vectorizer.fit_transform(df['cleaned_snippet'])  # Gunakan 'cleaned_snippet' yang sudah diproses\n",
    "\n",
    "# Ambil fitur kata kunci dari hasil TF-IDF\n",
    "tfidf_features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Konversi hasil TF-IDF menjadi DataFrame agar lebih mudah dibaca\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_features)\n",
    "\n",
    "# Tampilkan hasil TF-IDF untuk 5 baris pertama\n",
    "print(tfidf_df.head())\n",
    "\n",
    "# Simpan hasil TF-IDF ke file baru\n",
    "output_file = 'new-review-data/filter-snippet/tfidf_filtered_snippet_reviews_gensin.csv'\n",
    "tfidf_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Hasil TF-IDF disimpan ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menampilkan Kata Kunci Berdasarkan Skor TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 kata kunci untuk dokumen pertama:\n",
      "energy       0.368646\n",
      "upgrade      0.338216\n",
      "consume      0.210333\n",
      "response     0.210333\n",
      "excessive    0.210333\n",
      "hassle       0.210333\n",
      "struggle     0.210333\n",
      "chore        0.195118\n",
      "opinion      0.195118\n",
      "cap          0.195118\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Menampilkan kata-kata dengan skor TF-IDF tertinggi pada dokumen pertama\n",
    "tfidf_scores = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_features)\n",
    "top_words = tfidf_scores.iloc[0].sort_values(ascending=False).head(10)\n",
    "print(f\"Top 10 kata kunci untuk dokumen pertama:\\n{top_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/Campus/System-Retrieval-Information/system-retrieval-information/gensin/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999976 0.97253555 0.9862162  ... 0.96884036 0.9793917  0.9839121 ]\n",
      " [0.97253555 0.99999976 0.9705523  ... 0.9612145  0.96226656 0.9759674 ]\n",
      " [0.9862162  0.9705523  1.0000005  ... 0.9731432  0.9789413  0.981642  ]\n",
      " ...\n",
      " [0.96884036 0.9612145  0.9731432  ... 0.9999999  0.9755378  0.9726212 ]\n",
      " [0.9793917  0.96226656 0.9789413  ... 0.9755378  0.9999999  0.9841534 ]\n",
      " [0.9839121  0.9759674  0.981642   ... 0.9726212  0.9841534  0.9999996 ]]\n",
      "Hasil cosine similarity disimpan ke new-review-data/filter-snippet/cosine_similarity_gensin_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Muat model RoBERTa dan tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "# Fungsi untuk mendapatkan embeddings dari teks menggunakan RoBERTa\n",
    "def get_roberta_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Rata-rata embeddings dari token terakhir\n",
    "    return embeddings.squeeze().numpy()\n",
    "\n",
    "# Baca dataset yang sudah diproses\n",
    "input_file = 'new-review-data/filter-snippet/filtered_snippet_reviews_gensin.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Ambil ulasan yang telah diproses (misal kolom 'cleaned_snippet')\n",
    "if 'cleaned_snippet' not in df.columns:\n",
    "    raise ValueError(\"Kolom 'cleaned_snippet' tidak ditemukan dalam dataset. Periksa file input.\")\n",
    "\n",
    "# Ambil embeddings untuk setiap ulasan\n",
    "embeddings = [get_roberta_embeddings(text) for text in df['cleaned_snippet']]\n",
    "\n",
    "# Hitung cosine similarity antara setiap pasang ulasan\n",
    "cosine_similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Menampilkan hasil cosine similarity\n",
    "print(cosine_similarities)\n",
    "\n",
    "# Menyimpan hasil similarity ke dalam DataFrame\n",
    "cosine_sim_df = pd.DataFrame(cosine_similarities)\n",
    "\n",
    "# Simpan hasil cosine similarity ke file baru\n",
    "output_file = 'new-review-data/filter-snippet/cosine_similarity_gensin_reviews.csv'\n",
    "cosine_sim_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Hasil cosine similarity disimpan ke {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rekomendasi untuk review pertama:\n",
      "1. ve play game year experience player go gameplay good easy understand elemental reaction easy remember accommodate storyline plot good character pretty write love detail people know experience glitch fix time overall highly recommend game fun great time pass bore\n",
      "2. initially star review long review anymore good faith love art style game music amazing world beautiful month ago finish main story new patch update drop main story finish quickly character story quest game get stagnet thing ask hsr instead personally annoying love\n",
      "3. hard good rating thing worth play genshin impact story story like inazuma bad music rest experience gameplay level character talent artifact exploration quality life fix worth watch youtube story listen spotify music\n",
      "4. genshin deserve   star review great game nice quality character design story quest wonderful main story quest world quest annoying sit uninteresting dialogue end day perfectly fine need bit patience fit lot play style find like game m   mark short game\n",
      "5. start couple year ago feel like breath wild clone huge world climbing glide good fast reactive control fun combat impress free keep increase size world enhance ui add story add cool character new ability reason explore story voice act actually good start damn good get well free amazing\n",
      "6. game get unreasonable hate people play highly recommend game amazing year play bulkier phone crash lag happen low graphic setting character story worth\n",
      "7. improve experience little game setting take break fight game aesthetic worth time ve spend game story devs put guess rush head game loose perspective escape need game thank game hoyoverse\n",
      "8. pretty good game good graphic cool design character nice storyline voice act freely explore game high ar get boringi try like permanent mini game great game\n",
      "9. great game play year get tired major improvement term qol entire game generally artifact system change story dialogue take time voice go gacha not improve limit weapon banner get original   form bad play game excited lot restriction deceive audience\n",
      "10. gi fun adventure game play year easy ascent character need work hard get lucky strong characterweapon artifek player spend lot primogen intertwine fate not strong gold character weapon overall game fun developer add mark sign   lose forget farming\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk merekomendasikan ulasan berdasarkan kesamaan cosine\n",
    "def recommend_reviews(idx, cosine_sim_matrix, top_n=10):  # Mengubah top_n menjadi 10\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))  # Dapatkan skor kesamaan untuk review tertentu\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)  # Urutkan berdasarkan kesamaan\n",
    "    sim_scores = sim_scores[1:top_n+1]  # Ambil top N ulasan yang mirip\n",
    "    review_indices = [score[0] for score in sim_scores]\n",
    "    return review_indices\n",
    "\n",
    "# Contoh: Mengambil rekomendasi untuk ulasan pertama\n",
    "recommended_reviews = recommend_reviews(0, cosine_similarities, top_n=10)  # Mengubah top_n menjadi 10\n",
    "\n",
    "# Tampilkan ulasan yang direkomendasikan dengan penomoran\n",
    "print(\"\\nRekomendasi untuk review pertama:\")\n",
    "for i, idx in enumerate(recommended_reviews, 1):  # Menambahkan penomoran\n",
    "    print(f\"{i}. {df.iloc[idx]['cleaned_snippet']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     cleaned_snippet sentiment  sentiment_prob\n",
      "0  ve review decide edit response current opinion...   Negatif        0.561774\n",
      "1  fun wish fighting quest bunch talk run come qu...   Negatif        0.565175\n",
      "2  fun game enjoy story ton ton content clear bor...   Negatif        0.562104\n",
      "3  game phenomenal art style scenery stunning yes...   Negatif        0.560393\n",
      "4  love game incredibly laggy point unplayable gr...   Negatif        0.561833\n",
      "Hasil analisis sentimen disimpan ke new-review-data/filter-snippet/sentiment_analysis_gensin_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "# Muat model RoBERTa dan tokenizer untuk analisis sentimen\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "\n",
    "# Fungsi untuk menganalisis sentimen dari teks\n",
    "def sentiment_analysis(text):\n",
    "    # Tokenisasi teks\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Prediksi sentimen\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Konversi logits ke probabilitas menggunakan softmax\n",
    "    probs = softmax(logits, dim=-1)\n",
    "    \n",
    "    # Tentukan label sentimen (0 = Negatif, 1 = Positif)\n",
    "    sentiment = torch.argmax(probs, dim=-1).item()\n",
    "    \n",
    "    # Kembalikan hasil sentimen dan probabilitasnya\n",
    "    sentiment_label = 'Positif' if sentiment == 1 else 'Negatif'\n",
    "    sentiment_prob = probs[0][sentiment].item()\n",
    "    \n",
    "    return sentiment_label, sentiment_prob\n",
    "\n",
    "# Baca dataset yang sudah diproses\n",
    "input_file = 'new-review-data/filter-snippet/filtered_snippet_reviews_gensin.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Pastikan kolom 'cleaned_snippet' ada\n",
    "if 'cleaned_snippet' not in df.columns:\n",
    "    raise ValueError(\"Kolom 'cleaned_snippet' tidak ditemukan dalam dataset. Periksa file input.\")\n",
    "\n",
    "# Terapkan analisis sentimen untuk setiap ulasan\n",
    "df['sentiment'], df['sentiment_prob'] = zip(*df['cleaned_snippet'].apply(sentiment_analysis))\n",
    "\n",
    "# Simpan hasil analisis sentimen ke file baru\n",
    "output_file = 'new-review-data/filter-snippet/sentiment_analysis_gensin_reviews.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "# Tampilkan beberapa contoh hasil sentimen\n",
    "print(df[['cleaned_snippet', 'sentiment', 'sentiment_prob']].head())\n",
    "\n",
    "print(f\"Hasil analisis sentimen disimpan ke {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/Campus/System-Retrieval-Information/system-retrieval-information/gensin/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rebecca/Campus/System-Retrieval-Information/system-retrieval-information/gensin/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/rebecca/Campus/System-Retrieval-Information/system-retrieval-information/gensin/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Baca dataset yang sudah diproses (hasil analisis sentimen)\n",
    "input_file = 'new-review-data/filter-snippet/sentiment_analysis_gensin_reviews.csv'\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Misalkan kita memiliki ground truth tentang relevansi ulasan (untuk keperluan evaluasi)\n",
    "# Kolom 'relevance' adalah ground truth, yang bisa berisi 1 untuk relevan (positif) dan 0 untuk tidak relevan (negatif)\n",
    "# Contoh data ground truth, sesuaikan dengan dataset kamu\n",
    "df['relevance'] = df['sentiment'].apply(lambda x: 1 if x == 'Positif' else 0)\n",
    "\n",
    "# Split data untuk evaluasi (bisa menggunakan validasi silang atau split data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_snippet'], df['relevance'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Fungsi untuk menganalisis sentimen dan mendapatkan prediksi\n",
    "def get_sentiment_predictions(texts):\n",
    "    predictions = []\n",
    "    for text in texts:\n",
    "        sentiment, _ = sentiment_analysis(text)  # Gunakan fungsi sentiment_analysis yang sudah dibuat\n",
    "        predictions.append(1 if sentiment == 'Positif' else 0)  # 1 untuk positif, 0 untuk negatif\n",
    "    return predictions\n",
    "\n",
    "# Ambil prediksi sentimen untuk data uji\n",
    "y_pred = get_sentiment_predictions(X_test)\n",
    "\n",
    "# Hitung metrik evaluasi: Precision, Recall, F1-Score\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Tampilkan hasil evaluasi\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gensin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
