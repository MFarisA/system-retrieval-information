{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1: 18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal\n",
      "Classification.  The first edition of the DDC was published\n",
      "in 1876, the eighteenth ...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 2: Use Made of Technical Libraries Slater, M. This report is an analysis of 6300 acts of use\n",
      "in 104 technical libraries in the United Kingdom.\n",
      "Library use is only one aspect of the wider pattern of\n",
      "infor...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 3: Two Kinds of Power\n",
      "An Essay on Bibliographic Control Wilson, P. The relationships between the organization and control of writings\n",
      "and the organization and control of knowledge and information will\n",
      "in...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/Campus/System-Retrieval-Information/assigment-3/lsa-env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Step 1: Parse the dataset\n",
    "def parse_cisi_dataset(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "    # Split by document identifiers\n",
    "    documents = re.split(r'\\.I \\d+', content)[1:]  # Skip the first empty split\n",
    "    parsed_docs = []\n",
    "    for doc in documents:\n",
    "        # Extract relevant fields (Title, Author, and Abstract/Content)\n",
    "        title = re.search(r'\\.T(.*?)\\.A', doc, re.DOTALL)\n",
    "        author = re.search(r'\\.A(.*?)\\.W', doc, re.DOTALL)\n",
    "        abstract = re.search(r'\\.W(.*)', doc, re.DOTALL)\n",
    "        title_text = title.group(1).strip() if title else \"\"\n",
    "        author_text = author.group(1).strip() if author else \"\"\n",
    "        abstract_text = abstract.group(1).strip() if abstract else \"\"\n",
    "        full_text = f\"{title_text} {author_text} {abstract_text}\".strip()\n",
    "        parsed_docs.append(full_text)\n",
    "    return parsed_docs\n",
    "\n",
    "# Step 2: Preprocess and create the TF-IDF matrix\n",
    "def create_tfidf_matrix(documents):\n",
    "    # Adjusting the stop words and min_df to avoid empty vocabulary error\n",
    "    vectorizer = TfidfVectorizer(stop_words=None, min_df=1)  # No stop words removal, min_df=1\n",
    "    X_tfidf = vectorizer.fit_transform(documents)\n",
    "    return X_tfidf, vectorizer\n",
    "\n",
    "# Step 3: Apply Truncated SVD (LSA)\n",
    "def apply_lsa(tfidf_matrix, n_components=100):\n",
    "    svd = TruncatedSVD(n_components=n_components)\n",
    "    X_lsa = svd.fit_transform(tfidf_matrix)\n",
    "    return X_lsa, svd\n",
    "\n",
    "# Step 4: Retrieve relevant documents based on cosine similarity\n",
    "def retrieve_documents(query, tfidf_vectorizer, svd_model, lsa_matrix, top_n=5):\n",
    "    query_tfidf = tfidf_vectorizer.transform([query])\n",
    "    query_lsa = svd_model.transform(query_tfidf)  # Project query into LSA space\n",
    "    similarities = cosine_similarity(query_lsa, lsa_matrix)  # Cosine similarity\n",
    "    ranked_indices = np.argsort(similarities[0])[::-1][:top_n]  # Top N most similar documents\n",
    "    return ranked_indices, similarities[0][ranked_indices]\n",
    "\n",
    "# Step 5: Evaluate precision and recall\n",
    "def compute_precision_recall(retrieved_docs, ground_truth_relevant_docs):\n",
    "    # Create binary relevance for precision/recall calculation\n",
    "    y_true = [1 if doc_id in ground_truth_relevant_docs else 0 for doc_id in retrieved_docs]\n",
    "    y_pred = [1] * len(retrieved_docs)  # All retrieved documents are treated as relevant\n",
    "    # Compute precision and recall\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return precision, recall\n",
    "\n",
    "# Load and parse the dataset\n",
    "file_path = \"CISI.ALL\"\n",
    "documents = parse_cisi_dataset(file_path)\n",
    "\n",
    "# Debug: Check the first few parsed documents\n",
    "for i, doc in enumerate(documents[:3]):  # Print the first 3 documents\n",
    "    print(f\"Document {i+1}: {doc[:200]}...\\n{'-'*80}\")\n",
    "\n",
    "# Create the TF-IDF matrix\n",
    "X_tfidf, tfidf_vectorizer = create_tfidf_matrix(documents)\n",
    "\n",
    "# Apply LSA using Truncated SVD\n",
    "X_lsa, svd_model = apply_lsa(X_tfidf)\n",
    "\n",
    "# Sample query\n",
    "query = \"history of Dewey Decimal Classification\"\n",
    "\n",
    "# Retrieve top 5 most relevant documents\n",
    "top_indices, scores = retrieve_documents(query, tfidf_vectorizer, svd_model, X_lsa)\n",
    "\n",
    "# Ground truth relevance for the sample query (for example purposes, replace with actual labels)\n",
    "# Assuming that documents 1, 2, and 5 are relevant\n",
    "ground_truth_relevant_docs = [1, 2, 5]\n",
    "\n",
    "# Compute precision and recall\n",
    "precision, recall = compute_precision_recall(top_indices, ground_truth_relevant_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most relevant documents for the query:\n",
      "Document 260: (Score: 0.7782989082218531)\n",
      "Classification Practice in Britain.  Report on a survey of classification\n",
      "opinion and practice in Great Britain, with particular reference to the Dewey\n",
      "Decimal Classification Davison, K. The objective...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 1: (Score: 0.7017359622899058)\n",
      "18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal\n",
      "Classification.  The first edition of the DDC was published\n",
      "in 1876, the eighteenth ...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 1074: (Score: 0.6548754733289364)\n",
      "The DK (Decimal Classification) - a Multi-Faceted Classification Dahlberg, I. Backed up by numerical data  derived from an ASLIB analysis of the planned\n",
      "world-wide system of UNISIST, the author critic...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 335: (Score: 0.6165519059430933)\n",
      "Conceptual Basis of the Classification of Knowledge Wojciechowski, J.A. As far as philosophers are concerned, the Conference seems to be justified\n",
      "precisely because of the present state of the Classif...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 1066: (Score: 0.6014823876515021)\n",
      "A Modern Outline of Library Classification Mills, J. This outline is based mainly on lectures given at the North-Western\n",
      "Polytechnic to students studying for the Library Association's Registration\n",
      "Exa...\n",
      "--------------------------------------------------------------------------------\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the results\n",
    "print(\"Top 5 most relevant documents for the query:\")\n",
    "for i, index in enumerate(top_indices):\n",
    "    print(f\"Document {index + 1}: (Score: {scores[i]})\")\n",
    "    print(documents[index][:200] + \"...\")  # Print first 200 characters of the document for context\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Print precision and recall\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most relevant documents for the query:\n",
      "Document 260: (Score: 0.8484623239364907)\n",
      "Classification Practice in Britain.  Report on a survey of classification opinion and practice in Great Britain, with particular reference to the Dewey Decimal Classification .A Davison, K. .W   The objectives of the Sub-Committee in starting their enquiries were basically three-fold      1) To gath...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 1074: (Score: 0.8273151825699409)\n",
      "The DK (Decimal Classification) - a Multi-Faceted Classification .A Dahlberg, I. .W   Backed up by numerical data  derived from an ASLIB analysis of the planned world-wide system of UNISIST, the author critically investigates the claimed university of the U.D.C.  According to it, the so-called \"Univ...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 1141: (Score: 0.7985857718343811)\n",
      "Algebra of Classification .A Shreider, Yu. A. .W    Two alternative concepts of isomorphism of classification are examined.. It is shown that with the accuracy of up to isomorphism, the structure of a classification is characterized by a certain semigroup.. For an important type  of classifications,...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 1140: (Score: 0.7687991981173411)\n",
      "On the Symbolic Nature of Classifications .A Panova, N. S. Shreider, Yu. A. .W    The nature of an arbitrary classification is considered from the viewpoint of its sign function.. The structure of the taxons described by a given  classification is treated as the referent (the denotate).. The formati...\n",
      "--------------------------------------------------------------------------------\n",
      "Document 335: (Score: 0.7574726873992463)\n",
      "Conceptual Basis of the Classification of Knowledge .A Wojciechowski, J.A. .W   As far as philosophers are concerned, the Conference seems to be justified precisely because of the present state of the Classification of Knowledge.  For two thousand years, the Classification of Knowledge has been a ma...\n",
      "--------------------------------------------------------------------------------\n",
      "Precision: 0.2000\n",
      "Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "def load_cisi_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read().split('.I ')\n",
    "    \n",
    "    docs = []\n",
    "    for doc in data[1:]:\n",
    "        doc_lines = doc.strip().splitlines()\n",
    "        doc_id = doc_lines[0].strip()\n",
    "        doc_content = ' '.join(doc_lines[2:]).strip()\n",
    "        docs.append({'id': doc_id, 'content': doc_content})\n",
    "    \n",
    "    return pd.DataFrame(docs)\n",
    "\n",
    "# Load CISI dataset\n",
    "file_path = 'CISI.ALL'\n",
    "df = load_cisi_dataset(file_path)\n",
    "\n",
    "# Preprocess the data and remove stop words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "# Apply TF-IDF to the document corpus\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['content'])\n",
    "\n",
    "# Reduce the dimensionality with LSA (SVD)\n",
    "lsa = TruncatedSVD(n_components=100, random_state=42)\n",
    "lsa_matrix = lsa.fit_transform(tfidf_matrix)\n",
    "\n",
    "# Get user query and process it similarly to the document corpus\n",
    "def process_query(query):\n",
    "    query_tfidf = tfidf_vectorizer.transform([query])\n",
    "    query_lsa = lsa.transform(query_tfidf)\n",
    "    return query_lsa\n",
    "\n",
    "# Function to rank documents based on cosine similarity\n",
    "def rank_documents(query_lsa, lsa_matrix, df):\n",
    "    # Compute cosine similarity between the query and all document vectors\n",
    "    cosine_similarities = cosine_similarity(query_lsa, lsa_matrix)\n",
    "    similarity_scores = cosine_similarities.flatten()\n",
    "    \n",
    "    # Get the top N document indices sorted by similarity\n",
    "    top_n_idx = similarity_scores.argsort()[::-1]\n",
    "    top_n_scores = similarity_scores[top_n_idx]\n",
    "    \n",
    "    # Retrieve and print top N most relevant documents\n",
    "    print(\"Top 5 most relevant documents for the query:\")\n",
    "    for idx in range(5):\n",
    "        doc_id = df.iloc[top_n_idx[idx]]['id']\n",
    "        doc_content = df.iloc[top_n_idx[idx]]['content'][:300]  # Show first 300 characters\n",
    "        score = top_n_scores[idx]\n",
    "        print(f\"Document {doc_id}: (Score: {score})\")\n",
    "        print(f\"{doc_content}...\\n{'-'*80}\")\n",
    "\n",
    "# Precision and Recall Calculation (dummy relevance judgments for example purposes)\n",
    "def evaluate_precision_recall(retrieved_docs, relevant_docs):\n",
    "    y_true = np.array([1 if doc in relevant_docs else 0 for doc in retrieved_docs])\n",
    "    y_pred = np.array([1] * len(retrieved_docs))  # Assume all retrieved docs are relevant for now\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Example query\n",
    "query = \"Dewey Decimal Classification system\"\n",
    "\n",
    "# Process the query and rank documents\n",
    "query_lsa = process_query(query)\n",
    "rank_documents(query_lsa, lsa_matrix, df)\n",
    "\n",
    "# For evaluation, assume we have a list of relevant document IDs for the query\n",
    "relevant_docs = ['260', '1']  # These are hypothetical relevant document IDs\n",
    "retrieved_docs = df['id'].iloc[:5].tolist()  # Top 5 retrieved documents\n",
    "\n",
    "# Evaluate precision and recall\n",
    "evaluate_precision_recall(retrieved_docs, relevant_docs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsa-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
